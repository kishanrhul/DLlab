{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aims of this exercise are: \n",
    "    \n",
    "    - to gain experience in visualising the behaviour of a simple algorithm \n",
    "    \n",
    "    - to solve a simple data-fitting problem by gradient descent\n",
    "    \n",
    "    - to see some of the pathologies of gradient descent in the visualisation, and to try out alternative\n",
    "    optimisation methods that correct them (challenge 8 at the end). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math     # these commands allow us to use functions in the numpy and math modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d = [1, 2, 7.5, 3, -1, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type is d? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list is a core Python type which is not implemented as an array. To make an efficient numpy array, we need to use numpy commands. The most basic one is `array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([2,3, 7, -23.2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make numpy arrays by generation arrays directly full of random numbers, or zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b = np.random.random([3,5]) # uniform random numbers between 0 and 1\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoyingly, the corresponding function for generating normal random variates has a different syntax ! \n",
    "Can anyone find out why? \n",
    "Look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b = np.random.randn(4,2) # normally distributed random numbers with mean 0 and standard deviation 1\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get documentation and help on a function by typing a question mark in front of it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "?np.random.randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.zeros` has the same syntax as `np.random.random`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b = np.zeros([3,2])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising arrays and vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematical programming, you calculate large arrays of numbers. The only way of knowing what is going on is to visualise these arrays.\n",
    "\n",
    "There are two functions I use more frequently than any otherss: `imshow` and `plot`, both of which are in the `matplotlib.pyplot` module, which must be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # it is more convenient to type plt than matplotlib.pyplot every time\n",
    "\n",
    "# the following 'magic' instruction makes the plots appear in the notebook itself\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imshow : plotting a matrix as a colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.random([2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imshow( <matrix> )   # this shows the matrix as a colormap. Useful for seeing what is in the matrix\n",
    "colorbar()           # puts a colour scale to one side of the matrix, so that you can see what the values are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "v = np.cumsum( np.array( [1,2,3,17,-6])) # cumsum is used just to get a better looking curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot( v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(100,1)\n",
    "y = np.random.randn(100,1)\n",
    "\n",
    "plt.plot(x,y,'r.') # red dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'.')\n",
    "u = np.random.randn(20,1)\n",
    "v = np.random.randn(20,1)\n",
    "plt.plot(u,v,'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot above is plot on top of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "math.sqrt( np.mean(a * a) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([1,2],[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a line of best fit by gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some (synthetic) data to work with, consisting of x values and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_data = np.array( [x for x in range(0,10)])\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_data = 1.1 + 0.6 * x_data +  np.random.randn(x_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_data,y_data,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data $(x_1, y_1), \\ldots, (x_n, y_n)$\n",
    "\n",
    "Now we want to find the line of best fit.  How do we define a line? \n",
    "\n",
    "$\\hat{y} = m x + c$\n",
    "\n",
    "We put the hat over $y$ to show it is a prediction, not the data value. \n",
    "\n",
    "There are two parameters to find: $m$ and $c$\n",
    "\n",
    "Next, what is \"best fit\"?\n",
    "\n",
    "Given parameter values $m$ and $c$, our prediction of $y_i$ is\n",
    "\n",
    "$\\hat{y}_i = m x_i + c$\n",
    "\n",
    "We use mean squared prediction error as the measure of goodness of fit. \n",
    "\n",
    "$J = \\frac{1}{n}\\sum_{i=1}^n (\\hat{y}_i - y_i)^2$\n",
    "\n",
    "Let us create a function that calculates $J$ from $x$, $y$, $m$, and $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_J(x,y,m,c):\n",
    "    \"\"\"\n",
    "    x, y are ndarrays of the same length\n",
    "    m and c are floating point numbers giving gradient and intercept of a line\n",
    "    \"\"\"\n",
    "    yhat  = m * x + c\n",
    "    errs = (yhat - y)**2\n",
    "    J = np.mean( errs )\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m_values = np.linspace(0,1,200)\n",
    "c_values = np.linspace(0,2,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualise J as a function of m and c, for given data point with values x and y \n",
    "\n",
    "We do this with a colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "J_grid = np.zeros([m_values.size,c_values.size])\n",
    "\n",
    "for m_index in range(0,m_values.size):\n",
    "    for c_index in range(0,c_values.size):\n",
    "        J_grid[m_index,c_index] = calculate_J(x_data, y_data, m_values[m_index], c_values[c_index] )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(J_grid.transpose(), origin='lower',extent=[0,1,0,2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis corresponds to values of m; the y-axis corresponds to values of c. \n",
    "\n",
    "The colour shows the value of J for each combination of values of m and c. \n",
    "\n",
    "This colour map is a little hard to read. We are interested in the position of the p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(1. / J_grid.transpose(), origin='lower',extent=[0,1,0,2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def J_gradient(x,y,m,c):\n",
    "    \"\"\"\n",
    "    x, y are ndarrays of the same length\n",
    "    m and c are floating point numbers giving gradient and intercept of a line\n",
    "    \n",
    "    Returns the gradient J with respect to \n",
    "    \"\"\"\n",
    "    yhat = m*x + c \n",
    "    c_grads = 2 * (yhat - y)\n",
    "    m_grads = 2 * (yhat - y) * x\n",
    "    # now take the means of these, since J is the mean of the square error\n",
    "    c_grad = np.mean( c_grads )\n",
    "    m_grad = np.mean( m_grads )\n",
    "    return (m_grad, c_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "J_gradient(x_data,y_data,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "J_gradient(x_data,y_data, 0.6, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to optimise by gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = 0.0\n",
    "c = 0.0 \n",
    "\n",
    "m_path = [m]\n",
    "c_path = [c]\n",
    "\n",
    "n_iterations = 200\n",
    "learning_rate = 0.034\n",
    "\n",
    "for n in range(1,n_iterations):\n",
    "    m_grad, c_grad = J_gradient(x_data, y_data, m, c )\n",
    "    m = m - learning_rate * m_grad\n",
    "    c = c - learning_rate * c_grad\n",
    "    m_path.append(m)\n",
    "    c_path.append(c)\n",
    "    \n",
    "# at this point you may want to inspect m_path and c_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(1. / J_grid.transpose(), origin='lower',extent=[0,1,0,2])\n",
    "plt.colorbar()\n",
    "plt.plot(m_path,c_path,'r')\n",
    "plt.plot(m_path,c_path,'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks for you to do: \n",
    "    \n",
    "1. What happens if the learning rate is high? (Inspect the values on the paths)\n",
    "\n",
    "2. What is the highest value of the learning rate for which this process converges? \n",
    "\n",
    "3. Alter the code to record the value of J at each point along the path. For what values of learning rate does J decrease fastest? Can you plot how J decreases with the number of iterations? \n",
    "\n",
    "4. Try using gradient descent with <b>momentum</b>. Alter the code so that you record the previous change in m and in c, (call these m_change, and c_change). On the next loop iteration, use m_change = momentum * m_change - learning_rate * m_grad, and similarly for c.  Then change m by m = m + m_delta,  c = c + c_delta. \n",
    "\n",
    "5. What is the effect of increasing / reducing the x_data (that is, multiply the x_data by 10? and see what happens to the error surface, and gradient descent convergence.\n",
    "\n",
    "6. Intuitively, why is J so much more sensitive to m than to c here?  \n",
    "\n",
    "7. Can you plot the lines corresponding to the estimated values of m and c during optimisation ? \n",
    "\n",
    "8. After reading about RMSProp, can you implement RMSProp for this problem and visualise its behaviour? Does RMSProp have the same problem of instability as gradient descent, or not? \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
